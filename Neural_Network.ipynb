{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Random Optimization: Neural Network</center></h1>\n",
    "\n",
    "<h1><center>By Felicia Fryer</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from time import perf_counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlrose\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2 id=\"load_dataset\">Load the Cancer data</h2>\n",
    "The example is based on a dataset that is publicly available from the UCI Machine Learning Repository (Asuncion and Newman, 2007)[http://mlearn.ics.uci.edu/MLRepository.html]. The dataset consists of several hundred human cell sample records, each of which contains the values of a set of cell characteristics. The fields in each record are:\n",
    "\n",
    "|Field name|Description|\n",
    "|--- |--- |\n",
    "|ID|Clump thickness|\n",
    "|Clump|Clump thickness|\n",
    "|UnifSize|Uniformity of cell size|\n",
    "|UnifShape|Uniformity of cell shape|\n",
    "|MargAdh|Marginal adhesion|\n",
    "|SingEpiSize|Single epithelial cell size|\n",
    "|BareNuc|Bare nuclei|\n",
    "|BlandChrom|Bland chromatin|\n",
    "|NormNucl|Normal nucleoli|\n",
    "|Mit|Mitoses|\n",
    "|Class|Benign or malignant|\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "For the purposes of this example, we're using a dataset that has a relatively small number of predictors in each record. To download the data, we will use `!wget` to download it from IBM Object Storage.  \n",
    "__Did you know?__ When it comes to Machine Learning, you will likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: [Sign up now for free](http://cocl.us/ML0101EN-IBM-Offer-CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clump</th>\n",
       "      <th>UnifSize</th>\n",
       "      <th>UnifShape</th>\n",
       "      <th>MargAdh</th>\n",
       "      <th>SingEpiSize</th>\n",
       "      <th>BareNuc</th>\n",
       "      <th>BlandChrom</th>\n",
       "      <th>NormNucl</th>\n",
       "      <th>Mit</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Clump  UnifSize  UnifShape  MargAdh  SingEpiSize BareNuc  \\\n",
       "0  1000025      5         1          1        1            2       1   \n",
       "1  1002945      5         4          4        5            7      10   \n",
       "2  1015425      3         1          1        1            2       2   \n",
       "3  1016277      6         8          8        1            3       4   \n",
       "4  1017023      4         1          1        3            2       1   \n",
       "\n",
       "   BlandChrom  NormNucl  Mit  Class  \n",
       "0           3         1    1      2  \n",
       "1           3         2    1      2  \n",
       "2           3         1    1      2  \n",
       "3           3         7    1      2  \n",
       "4           3         1    1      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = pd.read_csv(\"cancer.csv\", delimiter=\",\")\n",
    "cancer[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first look at columns data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              int64\n",
       "Clump           int64\n",
       "UnifSize        int64\n",
       "UnifShape       int64\n",
       "MargAdh         int64\n",
       "SingEpiSize     int64\n",
       "BareNuc        object\n",
       "BlandChrom      int64\n",
       "NormNucl        int64\n",
       "Mit             int64\n",
       "Class           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the __BareNuc__ column includes some values that are not numerical. We can drop those rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             int64\n",
       "Clump          int64\n",
       "UnifSize       int64\n",
       "UnifShape      int64\n",
       "MargAdh        int64\n",
       "SingEpiSize    int64\n",
       "BareNuc        int64\n",
       "BlandChrom     int64\n",
       "NormNucl       int64\n",
       "Mit            int64\n",
       "Class          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = cancer[pd.to_numeric(cancer['BareNuc'], errors='coerce').notnull()]\n",
    "cancer['BareNuc'] = cancer['BareNuc'].astype('int')\n",
    "cancer.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1,  1,  1,  2,  1,  3,  1,  1],\n",
       "       [ 5,  4,  4,  5,  7, 10,  3,  2,  1],\n",
       "       [ 3,  1,  1,  1,  2,  2,  3,  1,  1],\n",
       "       [ 6,  8,  8,  1,  3,  4,  3,  7,  1],\n",
       "       [ 4,  1,  1,  3,  2,  1,  3,  1,  1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = cancer[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\n",
    "X = np.asarray(feature_df)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the model to predict the value of Class (that is, benign (=2) or malignant (=4)). As this field can have one of only two possible values, we need to change its measurement level to reflect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['Class'] = cancer['Class'].astype('int')\n",
    "y = np.asarray(cancer['Class'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we split our dataset into train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (478, 9) (478,)\n",
      "Test set: (205, 9) (205,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.30, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"modeling\">Benchmark using MLPClassifier</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation with Neural networks - 2 Layers, with Relu activation\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(9,9),activation = 'relu', max_iter=1500, solver='lbfgs')\n",
    "#scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "#print(scores)\n",
    "#print(np.std(scores))\n",
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "#print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: fit_time = 0.1795177309999758\n"
     ]
    }
   ],
   "source": [
    "#Train Model using MLPClassifier function\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(9,9), activation = 'relu', max_iter=1000, solver = 'lbfgs' )\n",
    "time_start = perf_counter()\n",
    "clf.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train: fit_time = {fit_time}')\n",
    "\n",
    "#train_accuracy = accuracy_score(y_train, )\n",
    "#print (f'train accuracy score = {train_accuracy2}')\n",
    "#train_accuracy1 = accuracy_score(y_train, yhat_train)\n",
    "#print (f'train accuracy score = {train_accuracy2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: fit_time = 0.0008121580000306494\n",
      "jaccard index:  0.9512195121951219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       132\n",
      "           1       0.90      0.97      0.93        73\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       205\n",
      "   macro avg       0.94      0.96      0.95       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      " samples avg       0.95      0.95      0.95       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start = perf_counter()\n",
    "yhat = clf.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "print (f'Test: fit_time = {fit_time}')\n",
    "\n",
    "#Evaulation\n",
    "jaccard = jaccard_similarity_score(y_test_hot, yhat)\n",
    "print(\"jaccard index: \",jaccard)\n",
    "print (classification_report(y_test_hot, yhat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: fit_time = 0.3530422930000441\n"
     ]
    }
   ],
   "source": [
    "#Train Model using MLPClassifier function - Sigmoid Funtion\n",
    "clf_sig = MLPClassifier(hidden_layer_sizes=(9,9), activation = 'logistic', max_iter=1000, solver = 'lbfgs' )\n",
    "time_start = perf_counter()\n",
    "clf_sig.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'Train: fit_time = {fit_time}')\n",
    "\n",
    "#train_accuracy = accuracy_score(y_train, )\n",
    "#print (f'train accuracy score = {train_accuracy2}')\n",
    "#train_accuracy1 = accuracy_score(y_train, yhat_train)\n",
    "#print (f'train accuracy score = {train_accuracy2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: fit_time = 0.0009876909999775307\n",
      "jaccard index:  0.9512195121951219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       132\n",
      "           1       0.91      0.96      0.93        73\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       205\n",
      "   macro avg       0.94      0.95      0.95       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      " samples avg       0.95      0.95      0.95       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_start = perf_counter()\n",
    "yhat_sig = clf_sig.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "print (f'Test: fit_time = {fit_time}')\n",
    "\n",
    "#Evaulation\n",
    "jaccard_sig = jaccard_similarity_score(y_test_hot, yhat_sig)\n",
    "print(\"jaccard index: \",jaccard_sig)\n",
    "print (classification_report(y_test_hot, yhat_sig))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"modeling\">Random Hill Climbing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 0.7264363169999797\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "clf_hill = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \n",
    "                                algorithm = 'random_hill_climb', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_hill.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'fit_time = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Labels for train set and assess accuracy\n",
    "#time_start = perf_counter()\n",
    "#yhat_hill = clf_hill.predict(X_train_scaled)\n",
    "#fit_time = perf_counter() - time_start\n",
    "#print (f'fit_time = {fit_time}')\n",
    "#train_accuracy = accuracy_score(y_train, yhat_hill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 0.0007461910000756689\n",
      "accuracy score = 0.9463414634146341\n",
      "f1 score:  0.9467119102396119\n",
      "jaccard index:  0.9463414634146341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       132\n",
      "           1       0.90      0.96      0.93        73\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       205\n",
      "   macro avg       0.94      0.95      0.94       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      " samples avg       0.95      0.95      0.95       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_hill_test = clf_hill.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy1 = accuracy_score(y_test_hot, yhat_hill_test)\n",
    "f1 = f1_score(y_test_hot, yhat_hill_test, average='weighted') \n",
    "jaccard1 = jaccard_similarity_score(y_test_hot, yhat_hill_test)\n",
    "print (f'fit_time = {fit_time}')\n",
    "print (f'accuracy score = {test_accuracy1}')\n",
    "print(\"f1 score: \", f1)\n",
    "print(\"jaccard index: \",jaccard1)\n",
    "print (classification_report(y_test_hot, yhat_hill_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 1.272307039999987\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "clf_hill_sig = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'sigmoid', \n",
    "                                algorithm = 'random_hill_climb', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_hill_sig.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'fit_time = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 0.0008163919999333302\n",
      "accuracy score = 0.6439024390243903\n",
      "f1 score:  0.504422088731273\n",
      "jaccard index:  0.6439024390243903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78       132\n",
      "           1       0.00      0.00      0.00        73\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       205\n",
      "   macro avg       0.32      0.50      0.39       205\n",
      "weighted avg       0.41      0.64      0.50       205\n",
      " samples avg       0.64      0.64      0.64       205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_hill_test_sig = clf_hill_sig.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy2 = accuracy_score(y_test_hot, yhat_hill_test_sig)\n",
    "f2 = f1_score(y_test_hot, yhat_hill_test_sig, average='weighted') \n",
    "jaccard2 = jaccard_similarity_score(y_test_hot, yhat_hill_test_sig)\n",
    "print (f'fit_time = {fit_time}')\n",
    "print (f'accuracy score = {test_accuracy2}')\n",
    "print(\"f1 score: \", f2)\n",
    "print(\"jaccard index: \",jaccard2)\n",
    "print (classification_report(y_test_hot, yhat_hill_test_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"modeling\">Simulated Annealing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 1.679088254999897\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "clf_sim = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \n",
    "                                algorithm = 'simulated_annealing', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_sim.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'fit_time = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 0.0007612040000140041\n",
      "test accuracy score = 0.9365853658536586\n",
      "f1 score:  0.9370231666468138\n",
      "jaccard index:  0.9365853658536586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       132\n",
      "           1       0.88      0.95      0.91        73\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       205\n",
      "   macro avg       0.93      0.94      0.93       205\n",
      "weighted avg       0.94      0.94      0.94       205\n",
      " samples avg       0.94      0.94      0.94       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_sim_test = clf_sim.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy3 = accuracy_score(y_test_hot, yhat_sim_test)\n",
    "f3 = f1_score(y_test_hot, yhat_sim_test, average='weighted') \n",
    "jaccard3 = jaccard_similarity_score(y_test_hot, yhat_sim_test)\n",
    "print (f'fit_time = {fit_time}')\n",
    "print (f'test accuracy score = {test_accuracy3}')\n",
    "print(\"f1 score: \", f3)\n",
    "print(\"jaccard index: \",jaccard3)\n",
    "print (classification_report(y_test_hot, yhat_sim_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Function Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 1.7124829910000017\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(7)\n",
    "clf_sim_sig = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'sigmoid', \n",
    "                                algorithm = 'simulated_annealing', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_sim_sig.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'fit_time = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 0.0005778360000476823\n",
      "test accuracy score = 0.9365853658536586\n",
      "f1 score:  0.9370231666468138\n",
      "jaccard index:  0.9365853658536586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       132\n",
      "           1       0.88      0.95      0.91        73\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       205\n",
      "   macro avg       0.93      0.94      0.93       205\n",
      "weighted avg       0.94      0.94      0.94       205\n",
      " samples avg       0.94      0.94      0.94       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_sim_test_sig = clf_sim_sig.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy4 = accuracy_score(y_test_hot, yhat_sim_test_sig)\n",
    "f4 = f1_score(y_test_hot, yhat_sim_test_sig, average='weighted') \n",
    "jaccard4 = jaccard_similarity_score(y_test_hot, yhat_sim_test_sig)\n",
    "print (f'fit_time = {fit_time}')\n",
    "print (f'test accuracy score = {test_accuracy4}')\n",
    "print(\"f1 score: \", f4)\n",
    "print(\"jaccard index: \",jaccard4)\n",
    "print (classification_report(y_test_hot, yhat_sim_test_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"modeling\">Genetic Algorithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 44.642368153999996\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(7)\n",
    "clf_gen = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'relu', \n",
    "                                algorithm = 'genetic_alg', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_gen.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'fit_time = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 0.000678228999959174\n",
      "accuracy score = 0.9512195121951219\n",
      "f1 score:  0.9514946841776111\n",
      "jaccard index:  0.9512195121951219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       132\n",
      "           1       0.91      0.96      0.93        73\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       205\n",
      "   macro avg       0.94      0.95      0.95       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      " samples avg       0.95      0.95      0.95       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_gen_test = clf_gen.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy5 = accuracy_score(y_test_hot, yhat_gen_test)\n",
    "f5 = f1_score(y_test_hot, yhat_gen_test, average='weighted') \n",
    "jaccard5 = jaccard_similarity_score(y_test_hot, yhat_gen_test)\n",
    "print (f'fit_time = {fit_time}')\n",
    "print (f'accuracy score = {test_accuracy5}')\n",
    "print(\"f1 score: \", f5)\n",
    "print(\"jaccard index: \",jaccard5)\n",
    "\n",
    "print (classification_report(y_test_hot, yhat_gen_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 21.83741524800007\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(7)\n",
    "clf_gen_sig = mlrose.NeuralNetwork(hidden_nodes = [2], activation = 'sigmoid', \n",
    "                                algorithm = 'genetic_alg', \n",
    "                                max_iters=1000, bias = True, is_classifier = True, \n",
    "                                learning_rate = 0.5, early_stopping = True, clip_max = 5, \n",
    "                                max_attempts = 100)\n",
    "time_start = perf_counter()\n",
    "clf_gen_sig.fit(X_train_scaled, y_train_hot)\n",
    "fit_time = perf_counter() - time_start\n",
    "print(f'fit_time = {fit_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time = 0.0008670600000186823\n",
      "accuracy score = 0.9463414634146341\n",
      "f1 score:  0.9468381879973526\n",
      "jaccard index:  0.9463414634146341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       132\n",
      "           1       0.89      0.97      0.93        73\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       205\n",
      "   macro avg       0.94      0.95      0.94       205\n",
      "weighted avg       0.95      0.95      0.95       205\n",
      " samples avg       0.95      0.95      0.95       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict Labels for test set and assess accuracy\n",
    "time_start = perf_counter()\n",
    "yhat_gen_test_sig = clf_gen_sig.predict(X_test_scaled)\n",
    "fit_time = perf_counter() - time_start\n",
    "test_accuracy6 = accuracy_score(y_test_hot, yhat_gen_test_sig)\n",
    "f6 = f1_score(y_test_hot, yhat_gen_test_sig, average='weighted') \n",
    "jaccard6 = jaccard_similarity_score(y_test_hot, yhat_gen_test_sig)\n",
    "print (f'fit_time = {fit_time}')\n",
    "print (f'accuracy score = {test_accuracy6}')\n",
    "print(\"f1 score: \", f6)\n",
    "print(\"jaccard index: \",jaccard6)\n",
    "\n",
    "print (classification_report(y_test_hot, yhat_gen_test_sig))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
